---
title: 2-2-2021
whiteboard_img: whiteboard-sa-2-2-2021.png
---

Students described projects from their experiential projects class -- Hunter Douglas and Arrow. Features with tons of cardinality.

[Whiteboard link](https://wbd.ms/share/v2/aHR0cHM6Ly93aGl0ZWJvYXJkLm1pY3Jvc29mdC5jb20vYXBpL3YxLjAvd2hpdGVib2FyZHMvcmVkZWVtLzczMTZlOWMwNjA3NzRkNjU4MjNiNWNlMTQzYjZlM2JkX0JCQTcxNzYyLTEyRTAtNDJFMS1CMzI0LTVCMTMxRjQyNEUzRA==)

## Model insights and explanation

When you get to the part in The Book that says that ML models are black boxes, don't believe it! Recent advances in ML
have new ways to [understand the relative impact of certain features, extract beta-like weights for values of features, and get row-level explanations for predictions](https://www.kaggle.com/learn/machine-learning-explainability).

## ROC curve and Precision-recall.

See [this draft blog post](https://daveeargle.com/2020/02/11/notes-on-ml-evaluation/) for some
discussion on the two, and also see [this sklearn jupyter notebook for precision-recall curve](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html) and [this one for ROC curves](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py).


## CYBR Network Security Analytics Project selections

I proposed that students create a CRISP-DM-style report for [networking-data-related datasets listed on the class repo page](https://classes.daveeargle.com/security-analytics-assignments/datasets) such as the following:

* Phishing Links
* CTU-13
* Kdd Cup 99
* Hybrid Analysis
* Sherlock

I _had_ mentioned Microsoft's two Kaggle competitions, and also the Spam email one, but on second thought, I don't think these are networking-related enough. These are options for projects in the future for this class, however.

There is also the option of replicating any of the feature-based ML papers that either CTU-13 or HinDom builds on.
Ones from HinDom include the following, following the following quote from HinDom (following following, following):

> "Traditional systems [3–6, 8, 21] mostly follow a feature based approach."

\[3] Manos Antonakakis, Roberto Perdisci, David Dagon,
Wenke Lee, and Nick Feamster. Building a dynamic reputation
system for dns. In USENIX security symposium,
pages 273–290, 2010.

\[4] Manos Antonakakis, Roberto Perdisci, Wenke Lee,
Nikolaos Vasiloglou, and David Dagon. Detecting malware
domains at the upper dns hierarchy. In USENIX
security symposium, volume 11, pages 1–16, 2011.

\[5] Manos Antonakakis, Roberto Perdisci, Yacin Nadji,
Nikolaos Vasiloglou, Saeed Abu-Nimeh, Wenke Lee,
and David Dagon. From throw-away traffic to bots:
Detecting the rise of dga-based malware. In USENIX
security symposium, volume 12, 2012.

\[6] Leyla Bilge, Sevil Sen, Davide Balzarotti, Engin Kirda,
and Christopher Kruegel. Exposure: A passive dns
analysis service to detect and report malicious domains.
ACM Transactions on Information and System Security
(TISSEC), 16(4):14, 2014.

\[8] Daiki Chiba, Takeshi Yagi, Mitsuaki Akiyama, Toshiki
Shibahara, Takeshi Yada, Tatsuya Mori, and Shigeki
Goto. Domainprofiler: Discovering domain names
abused in future. In 2016 46th Annual IEEE/IFIP International
Conference on Dependable Systems and Networks
(DSN), pages 491–502. IEEE, 2016.

\[21] Daiping Liu, Zhou Li, Kun Du, Haining Wang, Baojun
Liu, and Haixin Duan. Don’t let one rotten apple
spoil the whole barrel: Towards automated detection of
shadowed domains. In Proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications
Security, pages 537–552. ACM, 2017.
